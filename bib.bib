@incollection{menegatti2017gender,
  title={Gender bias and sexism in language},
  author={Menegatti, Michela and Rubini, Monica},
  booktitle={Oxford Research Encyclopedia of Communication},
  year={2017}
}

@article{larson2017gender,
  title={Gender as a variable in natural-language processing: Ethical considerations},
  author={Larson, Brian N},
  year={2017}
}

@article{braun2005cognitive,
  title={Cognitive effects of masculine generics in German: An overview of empirical findings},
  author={Braun, Friederike and Sczesny, Sabine and Stahlberg, Dagmar},
  year={2005},
  publisher={Walter de Gruyter}
}

@article{cuddy2008warmth,
  title={Warmth and competence as universal dimensions of social perception: The stereotype content model and the BIAS map},
  author={Cuddy, Amy JC and Fiske, Susan T and Glick, Peter},
  journal={Advances in experimental social psychology},
  volume={40},
  pages={61--149},
  year={2008},
  publisher={Elsevier}
}

@article{ng2007language,
  title={Language-based discrimination: Blatant and subtle forms},
  author={Ng, Sik Hung},
  journal={Journal of Language and Social Psychology},
  volume={26},
  number={2},
  pages={106--122},
  year={2007},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{eagly1994people,
  title={Are people prejudiced against women? Some answers from research on attitudes, gender stereotypes, and judgments of competence},
  author={Eagly, Alice H and Mladinic, Antonio},
  journal={European review of social psychology},
  volume={5},
  number={1},
  pages={1--35},
  year={1994},
  publisher={Taylor \& Francis}
}

@article{budziszewska2014men,
  title={Men against feminine job titles. The impact of gender--fair language on men’s and women’s perception of women},
  author={Budziszewska, M and Hansen, K and Bilewicz, M},
  journal={J. Lang. Soc. Psychol},
  volume={33},
  pages={681--691},
  year={2014}
}

@article{rubini2014strategic,
  title={The strategic role of language abstraction in achieving symbolic and practical goals},
  author={Rubini, Monica and Menegatti, Michela and Moscatelli, Silvia},
  journal={European review of social psychology},
  volume={25},
  number={1},
  pages={263--313},
  year={2014},
  publisher={Taylor \& Francis}
}

@article{maass1996language,
  title={Language and stereotyping},
  author={Maass, Anne and Arcuri, Luciano},
  journal={Stereotypes and stereotyping},
  pages={193--226},
  year={1996}
}

@article{sczesny2016can,
  title={Can gender-fair language reduce gender stereotyping and discrimination?},
  author={Sczesny, Sabine and Formanowicz, Magda and Moser, Franziska},
  journal={Frontiers in psychology},
  volume={7},
  pages={25},
  year={2016},
  publisher={Frontiers}
}

@article{stahlberg2007representation,
  title={Representation of the sexes in language},
  author={Stahlberg, Dagmar and Braun, Friederike and Irmen, Lisa and Sczesny, Sabine},
  journal={Social communication},
  pages={163--187},
  year={2007},
  publisher={New York and Hove: Psychology Press}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{kiritchenko2018examining,
  title={Examining gender and race bias in two hundred sentiment analysis systems},
  author={Kiritchenko, Svetlana and Mohammad, Saif M},
  journal={arXiv preprint arXiv:1805.04508},
  year={2018}
}

@misc{mikolov2013efficient,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{bolukbasi2016man,
  title={Man is to computer programmer as woman is to homemaker? debiasing word embeddings},
  author={Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T},
  journal={Advances in neural information processing systems},
  volume={29},
  pages={4349--4357},
  year={2016}
}

@inproceedings{pennington2014glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}


@misc{peters2018deep,
      title={Deep contextualized word representations}, 
      author={Matthew E. Peters and Mark Neumann and Mohit Iyyer and Matt Gardner and Christopher Clark and Kenton Lee and Luke Zettlemoyer},
      year={2018},
      eprint={1802.05365},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{zhao2019gender,
  title={Gender bias in contextualized word embeddings},
  author={Zhao, Jieyu and Wang, Tianlu and Yatskar, Mark and Cotterell, Ryan and Ordonez, Vicente and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1904.03310},
  year={2019}
}

@article{lee2018higher,
  title={Higher-order coreference resolution with coarse-to-fine inference},
  author={Lee, Kenton and He, Luheng and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1804.05392},
  year={2018}
}